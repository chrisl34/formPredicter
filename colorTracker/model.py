import numpy as np
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier

# Example dataset with labels

first_array = [1.0, 0.8043478260869565, 0.6195652173913043, 0.44565217391304346, 0.31521739130434784, 0.2391304347826087, 0.2391304347826087, 0.2717391304347826, 0.3804347826086957, 0.4891304347826087, 0.6086956521739131, 0.6847826086956522, 0.6521739130434783, 0.5869565217391305, 0.4891304347826087, 0.3804347826086957, 0.2608695652173913, 0.11956521739130435, 0.0]
second_array = [0.0, 0.0427807486631016, 0.13636363636363635, 0.24598930481283424, 0.32085561497326204, 0.3770053475935829, 0.42780748663101603, 0.47593582887700536, 0.5213903743315508, 0.5721925133689839, 0.6363636363636364, 0.7032085561497327, 0.7700534759358288, 0.8288770053475936, 0.8823529411764706, 0.9251336898395722, 0.9572192513368984, 0.9866310160427807, 1.0]

# Create the formatted array
formatted_array = [[first_array[i], second_array[i]] for i in range(len(first_array))]

formatted_array = np.array(formatted_array)
print(len(formatted_array))

# Print the formatted array
data = np.array([
    [[0.37126293167857605, 0.0], [0.49908378468476877, 0.02929349], [0.6244062115263831, 0.06551088319437681], [0.7395767175515741, 0.10828398933216565], [0.8369418081084965, 0.15724452272885392], [0.9097666873476502, 0.21276757441954008], [0.9604264999781287, 0.2791883960173952], [0.9903944635057949, 0.354094735230866], [1.0, 0.4336157071943282], [0.9895725315300948, 0.5138804270421572], [0.9594414801654306, 0.5910180099087287], [0.9099362679753584, 0.6611575709284186], [0.8392500193475927, 0.7209948782662728], [0.7343025842039992, 0.7730221796193998], [0.603234248729968, 0.8191316092580946], [0.45877924134947057, 0.8604536687418322], [0.31367179048648064, 0.8981188596300859], [0.18064612456497114, 0.9332576834823306], [0.07243647200891445, 0.9670006418580407], [0.0, 0.9999999999999999]], 
    [[1.0, 0.0], [0.7821143474158778, 0.02468855193848185], [0.5759799883971807, 0.05586326167596545], [0.3925379260359257, 0.09428291269371236], [0.24271530971609304, 0.1407317873512568], [0.13266277592394982, 0.1980732408269632], [0.058663875906839774, 0.26525270878045126], [0.01601186536533325, 0.33854486259851146], [0.0, 0.41422437366793563], [0.005921535511410003, 0.48856591337551514], [0.029069727600132128, 0.5578441531080416], [0.06737725156285582, 0.6189447605169531], [0.13839789176375833, 0.6753433918208396], [0.2346519355987169, 0.7286259404401456], [0.34169150883616484, 0.7791565622946219], [0.44506873724453716, 0.8272994133040188], [0.5303357465922681, 0.8734186493880867], [0.5830446626477905, 0.9178784264665756], [0.5939574363312412, 0.9604304806736548], [0.5753176473878606, 0.9999999999999998]],
    [[0.5792421987984441, 0.0], [0.6999572187313892, 0.03852529245988601], [0.8114685966098881, 0.08186024037014894], [0.9047103349334271, 0.1288641995041787], [0.9706164362014926, 0.1783965256353658], [1.0, 0.22955591842622547], [0.9863571206450414, 0.2858812054112363], [0.9370687457436002, 0.3472364937393688], [0.8622729559182382, 0.4114154044531857], [0.7721078317915154, 0.47621155859525044], [0.6767114539859936, 0.5394185772081259], [0.5862219031242343, 0.5988300813343741], [0.5056520410076288, 0.6525775443116646], [0.4181067277773832, 0.7017241660358635], [0.3261820716854761, 0.7481503796056415], [0.23576151867087497, 0.7936453004699042], [0.15272851467254855, 0.8399980440775563], [0.08296650562946245, 0.8889977258775028], [0.03235893748058677, 0.9424334613186487], [0.0, 1.0]],
    [[0.0, 0.0], [0.12720510086253506, 0.002943701931232723], [0.24717305798693448, 0.012203635248590139], [0.35230312670304753, 0.030123093830629277], [0.44897034061292795, 0.05815041357238293], [0.5584025649630573, 0.09476525423757054], [0.6724335047489763, 0.1386033555275914], [0.7819178401432758, 0.18833587133087548], [0.877710251318544, 0.24263395553585154], [0.950665418447371, 0.3001687620309489], [0.9916442708038827, 0.35961858938353675], [0.9999999999999999, 0.42603768781669527], [0.9837591439819883, 0.5019164936378525], [0.9478909611760448, 0.5833328903099199], [0.8973647100083659, 0.6663647612958071], [0.8371496489051481, 0.7470899900584248], [0.7722150362925878, 0.8215864600606831], [0.7065934411653325, 0.8862791629405687], [0.6284218991920966, 0.9448851131818107], [0.5378183515686928, 1.0]],
    [[0.4431085471452963, 0.0], [0.5778465194186798, 0.0180658461315073], [0.7041391752401353, 0.04322015855033012], [0.8100715792290154, 0.07672393739303007], [0.8844973281816337, 0.11997828520503473], [0.9374203447455969, 0.17638519703765565], [0.9750166754946296, 0.24390418043222895], [0.9962290005417563, 0.3184593961642378], [0.9999999999999999, 0.3959750050091645], [0.9852723539823839, 0.4723751677424922], [0.9509887426019317, 0.5435840451397046], [0.89492077041692, 0.6059288174723317], [0.8024719550162913, 0.6627207363353741], [0.6797011930881728, 0.7162336440437781], [0.5396875450186615, 0.7670877674625333], [0.39551007119385606, 0.8159033334566296], [0.2602478319998524, 0.8633005688910561], [0.14697988782274996, 0.9098997006308028], [0.06612596857596019, 0.9560624167924975], [0.0, 1.0]],
    [[0.0, 0.0], [0.16259314085555482, 0.02853379024629532], [0.31915483138993533, 0.0626913932302895], [0.46070942414421, 0.10284933909867788], [0.5784196827990541, 0.14941248653613814], [0.6807640299154909, 0.20535881751046126], [0.7747887594218612, 0.27017978095165507], [0.8570796563206747, 0.34057596158064896], [0.9242225056144415, 0.4132479441183725], [0.9728030923056717, 0.4848963132857549], [0.9994072013968761, 0.552221653803727], [1.0, 0.6122713162193403], [0.9658931848499995, 0.6679771901329985], [0.9035761394745965, 0.7211010274065766], [0.8237899386595624, 0.7719469275453257], [0.7372756571906709, 0.8208189900544958], [0.6547743698536942, 0.8680213144393383], [0.5870271514344054, 0.9138580002051022], [0.5416189860292074, 0.9582805129064691], [0.5070884509022048, 1.0]],   
])

labels = ['Kevin Durant', 'James Harden', 'Stephen Curry', 'Kyrie Irving', 'Klay Thompson', 'Damian Lillard']
labeled_arrays = [(labels[i], pd.DataFrame(data[i])) for i in range(len(data))]
labeled_df = pd.concat([df.assign(Label=label) for label, df in labeled_arrays])
X = labeled_df.drop('Label', axis=1)
y = labeled_df['Label']

knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')
knn.fit(X, y)
new_point = np.array(
   [[0.0, 0.0], [0.16259314085555482, 0.02853379024629532], [0.31915483138993533, 0.3], [0.46070942414421, 0.10284933909867788], [0.5784196827990541, 0.5], [0.6807640299154909, 0.20535881751046126], [0.7747887594218612, 0.27017978095165507], [0.8570796563206747, 0.34057596158064896], [0.9242225056144415, 0.4132479441183725], [0.9728030923056717, 0.4848963132857549], [0.9994072013968761, 0.552221653803727], [1.0, 0.6122713162193403], [0.9658931848499995, 0.6679771901329985], [0.9035761394745965, 0.7211010274065766], [0.8237899386595624, 0.7719469275453257], [0.7372756571906709, 0.8208189900544958], [0.6547743698536942, 0.8680213144393383], [0.5870271514344054, 0.9138580002051022], [0.5416189860292074, 0.9582805129064691], [0.5070884509022048, 1.0]],
)
prediction = knn.predict(new_point)
print("Predicted label:", prediction[0])
'''
knn = NearestNeighbors(n_neighbors=1, metric='euclidean')
knn.fit(data)

'''
'''
# Separate the coordinates and labels
X = data[:, :2].astype(float)
y = data[:, 2]

# Train the NearestNeighbors model
knn = NearestNeighbors(n_neighbors=1, metric='euclidean')
knn.fit(X)

# New data point to find the closest vector for
new_point = np.array([[8.0, 7.0]])

# Find the closest vector
distance, index = knn.kneighbors(new_point)

# Get the closest vector and its label
closest_vector = X[index[0][0]]
closest_label = y[index[0][0]]

print(f'Closest vector: {closest_vector}')
print(f'Label of the closest vector: {closest_label}')
'''
